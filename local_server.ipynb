{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "import accelerate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "secret_value_0 = os.getenv(\"HF_TOKEN\")\n",
    "secret_value_1 = os.getenv(\"NGROK_KEY\")\n",
    "model_chat = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "tokenizer_chat = AutoTokenizer.from_pretrained(model_chat, token=secret_value_0)\n",
    "pipeline_chat = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_chat,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    token=secret_value_0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "secret_value_3 = os.getenv(\"TAVILY_API_KEY\")\n",
    "tavily_cli = TavilyClient(api_key=secret_value_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "secret_value_4 = os.getenv(\"UPSTASH_PD\")\n",
    "redis_client = redis.StrictRedis(host=\"usw1-organic-yak-33107.upstash.io\", port='33107', password=secret_value_4, decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ngrok = redis_client.get('ngrok_link')\n",
    "except Exception as e:\n",
    "    link = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ques(in_s, out_s, query):\n",
    "    prompt = \"\"\"\n",
    "    <s>[INST] <<SYS>>\n",
    "    You are a helpful assistant that helps users generate questions. You will receive one question, and the question will be in JSON format. It will contain the question stem itself, no more than 4 options to answer the question, the correct option for the particular question, and the subject or topic related to the question.\n",
    "    You will do your best to generate one question, which should be similar in topic, style and difficulty of the question provided to you. It should be in JSON Format, and provide the question stem itself, the options, and the correct option to select.\n",
    "    You should ONLY have the JSON dictionary in your response.\n",
    "    <</SYS>>\n",
    "\n",
    "    {} [/INST] {} </s><s>[INST] {} [/INST]\n",
    "    \"\"\".format(in_s, out_s, query)\n",
    "    result = pipeline_chat(prompt)\n",
    "    return result\n",
    "def get_ans(in_s, out_s, query):\n",
    "    prompt = \"\"\"\n",
    "    <s>[INST] <<SYS>>\n",
    "    You are a helpful assistant that helps label correct answers for question. You will receive one question, and the question will be in JSON format. It will contain the question stem itself, no more than 4 options to answer the question, and information to help you answer the question.\n",
    "    You will do your best to match the correct option. Your answer should be in JSON format, providing the correct answer. If the information provided states that the correct answer is something, not in the options, change one of the options to accomodate for the correct option.\n",
    "    You should ONLY have the JSON dictionary in your response. The answer you provide should only be equal to A, B, C, D nothing else!\n",
    "    <</SYS>>\n",
    "\n",
    "    {} [/INST] {} </s><s>[INST] {} [/INST]\n",
    "    \"\"\".format(in_s, out_s, query)\n",
    "    result = pipeline_chat(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_in=\"{'topic': 'Evolution', 'question': 'Man's evolution is defined as:', 'options': ['Dysversion', 'Anthropogenesis', 'Convergence', 'ontogenesis'], 'answer': 'B'}\"\n",
    "sample_out=\"{'question': 'Which of the following mechanisms is NOT a driving force of evolution?', 'options': ['Natural selection', 'Genetic drift', 'Lamarckism', 'Geographical barriers'], 'answer': 'C'}\"\n",
    "ques_in=\"{'topic': 'Kinematics', 'question': 'Which of the following values is a vector?', 'options': ['Speed', 'Distance', 'Position', 'Velocity'], 'info': 'D. Velocity is a vector, as it has a direction'}\"\n",
    "ques_out=\"{'topic': 'Kinematics', 'question': 'Which of the following values is a vector?', 'options': ['Speed', 'Distance', 'Position', 'Velocity'], 'info': 'D. Velocity is a vector, as it has a direction', 'answer': 'D'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import threading\n",
    "from pyngrok import ngrok\n",
    "import json\n",
    "from flask_cors import CORS\n",
    "import re\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "@app.route('/run', methods=['GET'])\n",
    "def hello_world():\n",
    "    try:\n",
    "        data_in = request.args.get('msg')\n",
    "        data_out = get_ques(sample_in, sample_out, data_in)[0][\"generated_text\"].split(\"[/INST]\\n     \")[1]\n",
    "        pattern = r\"(?<=\\W)'(.*?)'(?=\\W)\"\n",
    "        output_string = re.sub(pattern, lambda x: f'\"{x.group(1)}\"', data_out)\n",
    "        dict_ans = json.loads(output_string)\n",
    "        query_tavily = dict_ans[\"question\"] + \": \"\n",
    "        opt_str = \"ABCD\"\n",
    "        for n in range(4):\n",
    "            query_tavily += opt_str[n] + \". \" + dict_ans[\"options\"][n] + \"  \"\n",
    "        context = tavily_cli.qna_search(query=query_tavily[:-2])\n",
    "        try:\n",
    "            del dict_ans[\"answer\"]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        dict_ans[\"info\"] = context\n",
    "        final_response = get_ans(ques_in, ques_out, dict_ans)[0][\"generated_text\"].split(\"[/INST]\\n     \")[1]\n",
    "        return jsonify({\"output\": final_response})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def run_flask():\n",
    "    app.run(port=6060)\n",
    "\n",
    "ngrok_auth_token = secret_value_1\n",
    "ngrok.set_auth_token(ngrok_auth_token)\n",
    "public_url = ngrok.connect(6060)\n",
    "threading.Thread(target=run_flask).start()\n",
    "pattern_link = r\"https?://\\S+\"\n",
    "matches = str(re.findall(pattern_link, str(public_url))[0])[:-1]\n",
    "redis_client.set('ngrok_link', matches+\"/\")\n",
    "print(f\"Access your Flask app at: {public_url}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
